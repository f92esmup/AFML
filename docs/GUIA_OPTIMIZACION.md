# ğŸ“Š GUÃA COMPLETA DE OPTIMIZACIÃ“N DE HIPERPARÃMETROS

## ğŸ¯ Objetivo

Encontrar la **mejor combinaciÃ³n de parÃ¡metros** para maximizar el **Sortino Ratio** del agente de trading.

---

## ğŸ§  Â¿CÃ³mo funciona?

### **BÃºsqueda Bayesiana con Optuna (TPE)**

No es una bÃºsqueda aleatoria, es **inteligente**:

```
Trial 1:  ParÃ¡metros aleatorios      â†’ Sortino = -5.2
Trial 2:  Aprende del Trial 1        â†’ Sortino = -3.1  âœ… Mejor
Trial 3:  Aprende de 1 y 2           â†’ Sortino = 1.8   âœ… Mucho mejor
Trial 10: Converge a zona prometedora â†’ Sortino = 3.2   âœ… Excelente
...
Trial 50: Encuentra Ã³ptimo local     â†’ Sortino = 4.5   â­ MEJOR
```

**Cada trial aprende de los anteriores** â†’ Converge a buenos parÃ¡metros mÃ¡s rÃ¡pido que bÃºsqueda aleatoria.

---

## ğŸ“¦ ParÃ¡metros Optimizados

### **1ï¸âƒ£ MODELO SAC (Soft Actor-Critic)**

| ParÃ¡metro | Rango | Tipo | ExplicaciÃ³n |
|-----------|-------|------|-------------|
| `learning_rate` | `[1e-5, 1e-3]` | Log scale | **Velocidad de aprendizaje**. Muy bajo = aprende lento, muy alto = inestable |
| `batch_size` | `[64, 128, 256, 512]` | CategÃ³rico | **TamaÃ±o de lote**. MÃ¡s grande = mÃ¡s estable pero mÃ¡s memoria |
| `gamma` | `[0.95, 0.999]` | Float | **Factor de descuento**. 0.95 = corto plazo, 0.999 = largo plazo |
| `tau` | `[0.001, 0.02]` | Float | **Soft update**. QuÃ© tan rÃ¡pido actualiza target networks |
| `ent_coef_target` | `[0.05, 0.3]` | Float | **ExploraciÃ³n**. MÃ¡s alto = mÃ¡s exploraciÃ³n vs explotaciÃ³n |
| `learning_starts` | `[1000, 10000]` | Int | **Pasos antes de entrenar**. Llena el buffer primero |
| `gradient_steps` | `[-1, 1, 2]` | CategÃ³rico | **Updates por step**. -1 = mismo que env steps |
| `buffer_size` | `[100k, 500k, 1M]` | CategÃ³rico | **Replay buffer**. Memoria histÃ³rica de experiencias |

**Â¿Por quÃ© estos rangos?**
- `learning_rate`: Basado en literatura de SAC + trading (tÃ­picamente 1e-4 a 5e-4)
- `batch_size`: Potencias de 2 por eficiencia GPU
- `gamma`: Trading requiere balance entre corto y largo plazo
- `buffer_size`: MÃ¡s grande = aprende de mÃ¡s historia, pero mÃ¡s RAM

---

### **2ï¸âƒ£ ENTORNO DE TRADING**

| ParÃ¡metro | Rango | ExplicaciÃ³n |
|-----------|-------|-------------|
| `window_size` | `[20, 30, 50, 100]` | **Velas de historia**. 20 = ~1 dÃ­a (1h), 100 = ~4 dÃ­as |
| `factor_aversion_riesgo` | `[1.0, 5.0]` | **AversiÃ³n al riesgo**. 1 = neutral, 5 = muy conservador |
| `max_drawdown_permitido` | `[0.10, 0.25]` | **PÃ©rdida mÃ¡xima tolerada**. 10% a 25% |
| `factor_escala_recompensa` | `[50.0, 200.0]` | **Escala de rewards**. Normaliza % a rango [-1, 1] |

**Pesos de Recompensa Multifactorial:**

| Peso | Rango | Componente |
|------|-------|------------|
| `peso_retorno_base` | `[0.5, 2.0]` | **Cambio en equity** (principal) |
| `peso_temporal` | `[0.1, 0.5]` | **PenalizaciÃ³n temporal** por mantener pÃ©rdidas |
| `peso_gestion` | `[0.05, 0.4]` | **Eficiencia en cierres** (bonifica cierre ganador) |
| `peso_drawdown` | `[0.05, 0.3]` | **ProtecciÃ³n contra ruina** (penaliza DD grandes) |

**Umbrales:**

| ParÃ¡metro | Rango | PropÃ³sito |
|-----------|-------|-----------|
| `umbral_perdida_pct` | `[0.001, 0.01]` | 0.1%-1%. PÃ©rdida mÃ­nima para activar penalizaciÃ³n |
| `umbral_ganancia_pct` | `[0.001, 0.01]` | 0.1%-1%. Ganancia mÃ­nima para bonificar |
| `penalizacion_no_operar` | `[0.0, 0.2]` | Anti-inacciÃ³n cuando equity cae |

**Â¿Por quÃ© estos pesos?**
- Suman ~2.0 total para balance
- `peso_retorno_base` es el mayor (principal driver)
- Los demÃ¡s modulan comportamiento (riesgo, eficiencia, etc.)

---

### **3ï¸âƒ£ ARQUITECTURA DE RED NEURONAL**

| ParÃ¡metro | Rango | ExplicaciÃ³n |
|-----------|-------|-------------|
| `n_layers` | `[2, 3]` | **Profundidad**. MÃ¡s capas = mÃ¡s capacidad pero mÃ¡s lento |
| `layer_size` | `[128, 256, 512]` | **Neuronas por capa**. MÃ¡s = mÃ¡s capacidad |
| `log_std_init` | `[-4.0, -2.0]` | **DesviaciÃ³n estÃ¡ndar inicial**. Afecta exploraciÃ³n temprana |
| `n_critics` | `[2, 3]` | **NÃºmero de Q-networks**. Previene sobreestimaciÃ³n |

**Arquitecturas posibles:**
- `[128, 128]` - RÃ¡pida, menos capacidad
- `[256, 256]` - Balance (default tÃ­pico)
- `[512, 512]` - MÃ¡xima capacidad, mÃ¡s lenta
- `[256, 256, 256]` - 3 capas, muy expresiva

---

### **4ï¸âƒ£ PORTAFOLIO**

| ParÃ¡metro | Rango | ExplicaciÃ³n |
|-----------|-------|-------------|
| `apalancamiento` | `[5.0, 20.0]` | **Multiplicador de capital**. 5x a 20x (Binance Futures) |

> **Nota**: `comision` y `slippage` estÃ¡n **fijos** (0.1%) para ser realistas con Binance.

---

## ğŸ“ˆ MÃ©tricas Calculadas

El sistema calcula **5 mÃ©tricas** pero **optimiza solo Sortino Ratio**:

### **1. Sortino Ratio** â­ (MÃ‰TRICA OBJETIVO)

```python
Sortino = (Retorno promedio - 0) / DesviaciÃ³n estÃ¡ndar de retornos negativos
```

**Â¿Por quÃ© Sortino y no Sharpe?**
- Sharpe penaliza **toda** la volatilidad (incluso ganancias)
- Sortino penaliza **solo** volatilidad a la baja (pÃ©rdidas)
- En trading, queremos ganancias volÃ¡tiles, no pÃ©rdidas volÃ¡tiles

**Valores tÃ­picos:**
- `< 0`: Perdiendo dinero
- `0-1`: Pobre
- `1-2`: Aceptable
- `2-3`: Bueno
- `> 3`: Excelente

### **2. Sharpe Ratio** (ComparaciÃ³n)

```python
Sharpe = (Retorno promedio - 0) / DesviaciÃ³n estÃ¡ndar total
```

### **3. Total Return** (Ganancia bruta)

```python
Total Return = (Equity final - Equity inicial) / Equity inicial
```

### **4. Max Drawdown** (Peor pÃ©rdida)

```python
Max DD = max((Equity mÃ¡ximo - Equity actual) / Equity mÃ¡ximo)
```

### **5. Win Rate** (% operaciones ganadoras)

```python
Win Rate = Operaciones ganadoras / Total operaciones
```

---

## ğŸš€ Uso del Sistema

### **OptimizaciÃ³n RÃ¡pida (10 trials de prueba)**

```bash
python3 hyperparameter_tuning.py \
  --symbol BTCUSDT \
  --interval 1h \
  --train-start-date 2024-01-01 \
  --train-end-date 2024-02-01 \
  --eval-start-date 2024-02-02 \
  --eval-end-date 2024-03-01 \
  --n-trials 10 \
  --timesteps-per-trial 3000
```

**Tiempo estimado:** ~30-60 min (depende de GPU/CPU)

### **OptimizaciÃ³n Completa (100 trials)**

```bash
python3 hyperparameter_tuning.py \
  --symbol BTCUSDT \
  --interval 1h \
  --train-start-date 2024-01-01 \
  --train-end-date 2024-06-01 \
  --eval-start-date 2024-06-02 \
  --eval-end-date 2024-09-01 \
  --n-trials 100 \
  --timesteps-per-trial 10000
```

**Tiempo estimado:** ~8-12 horas

### **Opciones Avanzadas**

```bash
# Optimizar solo SAC (ignorar entorno/network)
--optimize-sac --no-optimize-env --no-optimize-network

# Cambiar directorio de salida
--output-dir custom_optimization

# Ajustar episodios de evaluaciÃ³n
--n-eval-episodes 3

# Usar archivo de configuraciÃ³n custom
--config mi_config.yaml
```

---

## ğŸ“Š Resultados

### **Archivos Generados**

```
optimizaciones/
â””â”€â”€ optimization_BTCUSDT_1h_20251007_110025/
    â”œâ”€â”€ best_params.yaml          # â­ MEJORES PARÃMETROS
    â”œâ”€â”€ optimization.log          # Log completo
    â”œâ”€â”€ tuning_BTCUSDT_1h.db     # Base de datos Optuna
    â””â”€â”€ trials_history.csv        # Historial de todos los trials
```

### **Contenido de `best_params.yaml`**

```yaml
optimization_metadata:
  best_trial: 47
  n_trials: 100
  optimization_date: '2025-10-07T11:00:42'
  
best_metrics:
  sortino_ratio: 4.52        # â­ Excelente
  sharpe_ratio: 3.89
  total_return: 0.45         # +45%
  max_drawdown: 0.12         # -12%
  final_equity: 14500.0
  
best_params:
  # SAC
  learning_rate: 0.000234
  batch_size: 256
  gamma: 0.987
  # ... todos los parÃ¡metros optimizados
```

---

## ğŸ”§ Aplicar Mejores ParÃ¡metros

### **OpciÃ³n 1: Script AutomÃ¡tico**

```bash
python3 scripts/apply_best_params.py \
  optimizaciones/optimization_20251007_110025/best_params.yaml
```

Esto:
1. âœ… Crea backup de `config.yaml` â†’ `config.yaml.backup`
2. âœ… Actualiza `config.yaml` con mejores parÃ¡metros
3. âœ… Muestra resumen de cambios

### **OpciÃ³n 2: Manual**

Copia los valores de `best_params.yaml` a `src/train/config/config.yaml`.

---

## ğŸ“‰ VisualizaciÃ³n de Resultados

### **Dashboard Interactivo de Optuna**

```bash
optuna-dashboard sqlite:///optimizaciones/optimization_20251007_110025/tuning_BTCUSDT_1h.db
```

Abre en: `http://localhost:8080`

**Visualizaciones disponibles:**
- ğŸ“ˆ EvoluciÃ³n del Sortino Ratio por trial
- ğŸ“Š Importancia de cada parÃ¡metro (cuÃ¡les afectan mÃ¡s)
- ğŸ¯ Parallel coordinates (relaciones entre parÃ¡metros)
- ğŸ“‰ Slice plots (efecto individual de cada parÃ¡metro)

---

## ğŸ§ª Estrategias de OptimizaciÃ³n

### **Estrategia 1: ExploraciÃ³n amplia**

```bash
--n-trials 100 --timesteps-per-trial 5000
```

âœ… Explora mucho espacio de bÃºsqueda  
âœ… Trials rÃ¡pidos  
âŒ Menos precisiÃ³n por trial

### **Estrategia 2: ExplotaciÃ³n precisa**

```bash
--n-trials 30 --timesteps-per-trial 20000
```

âœ… Cada trial mÃ¡s preciso  
âŒ Menos exploraciÃ³n  
âŒ MÃ¡s lento

### **Estrategia 3: HÃ­brida (Recomendada)**

```bash
# Fase 1: ExploraciÃ³n rÃ¡pida
--n-trials 50 --timesteps-per-trial 5000

# Fase 2: Refinamiento (usa mejores params de Fase 1)
--n-trials 20 --timesteps-per-trial 15000
```

---

## âš™ï¸ Ajustar Rangos de BÃºsqueda

### **Archivo:** `src/train/optimization/ranges.py`

**Ejemplo: Hacer bÃºsqueda mÃ¡s conservadora**

```python
# Antes
'max_drawdown_permitido': trial.suggest_float('max_drawdown_permitido', 0.10, 0.25)

# DespuÃ©s (mÃ¡s conservador, 5%-15%)
'max_drawdown_permitido': trial.suggest_float('max_drawdown_permitido', 0.05, 0.15)
```

**Ejemplo: Probar learning rates mÃ¡s altos**

```python
# Antes
'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)

# DespuÃ©s
'learning_rate': trial.suggest_float('learning_rate', 5e-5, 5e-3, log=True)
```

---

## ğŸ“ InterpretaciÃ³n de Resultados

### **Â¿QuÃ© es un buen Sortino Ratio?**

| Sortino | InterpretaciÃ³n | AcciÃ³n |
|---------|----------------|--------|
| `< 0` | Perdiendo dinero | âŒ Revisar estrategia completa |
| `0-1` | Retorno pobre | ğŸŸ¨ Optimizar mÃ¡s o cambiar perÃ­odo |
| `1-2` | Aceptable | ğŸŸ© Probar con mÃ¡s datos/timesteps |
| `2-3` | Bueno | âœ… Listo para backtesting extenso |
| `> 3` | Excelente | â­ Considerar trading real (con precauciÃ³n) |

### **Â¿El mejor trial tiene overfitting?**

**SeÃ±ales de alerta:**
- Sortino muy alto (> 5) pero Max DD tambiÃ©n alto
- Win Rate > 80% (poco realista)
- Total Return > 100% en perÃ­odo corto

**SoluciÃ³n:**
- Validar en **perÃ­odo out-of-sample** diferente
- Usar **k-fold walk-forward** (implementar despuÃ©s)
- Probar en datos de otro sÃ­mbolo (ej: ETHUSDT)

---

## ğŸ“š Recursos Adicionales

- **Optuna Docs**: https://optuna.readthedocs.io/
- **SAC Paper**: https://arxiv.org/abs/1801.01290
- **Sortino Ratio**: https://en.wikipedia.org/wiki/Sortino_ratio

---

## â“ FAQ

### **Â¿Puedo pausar y reanudar la optimizaciÃ³n?**

SÃ­, Optuna guarda estado en la base de datos SQLite. Reinicia con:

```bash
# Mismo comando, aÃ±adirÃ¡ mÃ¡s trials a la misma base de datos
python3 hyperparameter_tuning.py ... --n-trials 50
```

### **Â¿CÃ³mo saber quÃ© parÃ¡metros son mÃ¡s importantes?**

En el dashboard de Optuna, ve a **"Hyperparameter Importance"**.

### **Â¿Puedo optimizar otros parÃ¡metros?**

SÃ­, edita `src/train/optimization/ranges.py` y aÃ±ade:

```python
'mi_parametro': trial.suggest_float('mi_parametro', min_val, max_val)
```

### **Â¿Necesito GPU?**

No es obligatorio, pero **acelera mucho** (3-5x mÃ¡s rÃ¡pido). El sistema detecta GPU automÃ¡ticamente.

---

## ğŸ› ï¸ Troubleshooting

### **Error: "Out of memory"**

Reduce `batch_size` o `buffer_size` en los rangos.

### **Trials muy lentos**

Reduce `--timesteps-per-trial` a 3000-5000.

### **Sortino siempre negativo**

- Revisa que los datos sean correctos (suficientes velas)
- Prueba con perÃ­odo diferente (bull market vs bear market)
- Verifica que la funciÃ³n de recompensa tiene sentido

---

**ğŸ¯ TIP FINAL:** Empieza con 10-20 trials rÃ¡pidos para validar que todo funciona, luego haz una optimizaciÃ³n completa de 100+ trials.
